---
layout: page
title: "X10'11 Program"
alias: "x1011-program"
category: "workshop"
redirect_from: /workshop/cfp/program.html
---
<p><strong><span style="font-family: Arial; font-size: small;">8:30 Welcome - Michael Hind</span></strong> [<a href="http://x10.sourceforge.net/documentation/papers/X10Workshop2011/Welcome.ppt">Slides</a>]<br /> <br /> <strong><span style="font-family: Arial; font-size: small;"> 8:40 X10 in a Nutshell </span></strong><span style="font-family: Arial; font-size: small;">by <strong>Vijay Saraswat&nbsp;</strong> [</span><a href="http://x10.sourceforge.net/documentation/papers/X10Workshop2011/X10Day-Overview.ppt">Slides</a>] Video [<a href="http://www.youtube.com/watch?v=R1_3J5sejsU">Part 1</a>] [<a href="http://www.youtube.com/watch?v=DJHD9L6sVUw">Part 2</a>] [<a href="http://www.youtube.com/watch?v=ZqmF1-GWxLM">Part 3</a>]</p>
<p><br /> <span style="font-family: sans-serif; font-size: small;"><strong>9:10 Session I, </strong></span><span style="font-family: sans-serif; font-size: small;">Chair: <strong>Steve Blackburn</strong></span><br /> <em><span style="font-family: sans-serif; font-size: small;"><a href="#2">A Performance Model for X10 Applications</a></span></em>&nbsp; [<a href="http://dl.acm.org/citation.cfm?id=2212737&amp;amp;CFID=102411363&amp;amp;CFTOKEN=78064996">Paper</a>] [<a href="http://x10.sourceforge.net/documentation/papers/X10Workshop2011/perfmodel.ppt">Slides</a>]<br /> <span style="font-family: sans-serif; font-size: small;">by David Grove, Olivier Tardieu, David Cunningham, Ben Herta, Igor Peshansky and Vijay Saraswat</span><br /> <br /> <em><span style="font-family: sans-serif; font-size: small;"><a href="#1">Parallel Programming: Design of an Overview Class</a></span></em> [<a href="http://dl.acm.org/citation.cfm?id=2212738&amp;amp;CFID=102411363&amp;amp;CFTOKEN=78064996">Paper</a>] [<a href="http://x10.sourceforge.net/documentation/papers/X10Workshop2011/x10_ws.pdf">Slides</a>]<br /> <span style="font-family: sans-serif; font-size: small;">by Christoph von Praun</span><br /> <br /> <span style="font-family: sans-serif; font-size: small;"><strong>10:10 Break</strong></span><br /> <br /> <span style="font-family: sans-serif; font-size: small;"><strong>10:40 Session II, </strong>Chair: <strong>Jens Palsberg </strong></span><br /> <em><span style="font-family: sans-serif; font-size: small;"><a href="#5">Object Initialization in X10</a></span></em> [<a href="http://x10.sourceforge.net/documentation/papers/X10Workshop2011/Object Initialization in X10.pptx">Slides</a>]<br /> <span style="font-family: sans-serif; font-size: small;">by Yoav Zibin, David Cunningham, Igor Peshansky, and Vijay Saraswat</span><br /> <br /> <em><span style="font-family: sans-serif; font-size: small;"><a href="#4">Compiling X10 to Java</a></span></em> [<a href="http://dl.acm.org/citation.cfm?id=2212739&amp;amp;CFID=102411363&amp;amp;CFTOKEN=78064996">Paper</a>] [<a href="http://x10.sourceforge.net/documentation/papers/X10Workshop2011/CompilingX10ToJavaSlides.pdf">Slides</a>]<br /> <span style="font-family: sans-serif; font-size: small;">by Mikio Takeuchi, Yuki Makino, Kiyokuni Kawachiya, Hiroshi Horii, Toyotaro Suzumura, Toshio Suganuma, and Tamiya Onodera</span><br /> <br /> <em><span style="font-family: sans-serif; font-size: small;"><a href="#6">Work-Stealing by Stealing States from Live Stack Frames of a Running Application</a></span></em>&nbsp; [<a href="http://x10.sourceforge.net/documentation/papers/X10Workshop2011/Kumarx10ws.pdf">Slides</a>]<br /> <span style="font-family: sans-serif; font-size: small;">by Vivek Kumar, Daniel Frampton, David Grove, Olivier Tardieu, and Steve Blackburn</span><br /> <br /> <br /> <span style="font-family: sans-serif; font-size: small;"><strong>12:10 Lunch</strong></span><br /> <br /> <span style="font-family: sans-serif; font-size: small;"><strong>1:30 Session III</strong></span><span style="font-family: sans-serif; font-size: small;"><strong>, </strong>Chair:<strong> Vivek Sarkar</strong></span><br /> <em><span style="font-family: sans-serif; font-size: small;"><a href="#9">Using the Cowichan Problems to Investigate the Programmability of X10 Programming System</a></span></em>&nbsp; [<a href="http://dl.acm.org/citation.cfm?id=2212740&amp;amp;CFID=102411363&amp;amp;CFTOKEN=78064996">Paper</a>] [<a href="http://x10.sourceforge.net/documentation/papers/X10Workshop2011/X10Experience.pdf">Slides</a>]<br /> <span style="font-family: sans-serif; font-size: small;">by Jeeva Paudel and Jose Nelson Amaral</span><br /> <br /> <em><span style="font-family: sans-serif; font-size: small;"><a href="#7">X10 implementation of Parallel Option Pricing with BSDE method</a></span></em> [<a href="http://dl.acm.org/citation.cfm?id=2212741&amp;amp;CFID=102411363&amp;amp;CFTOKEN=78064996">Paper</a>]<br /> <span style="font-family: sans-serif; font-size: small;">by Hui LIU, Ying Peng, DaiZhen Wei and Bin Dai</span><br /> <br /> <em><span style="font-family: sans-serif; font-size: small;"><a href="#8">Distributed deductive databases, declaratively: The L10 logic programming language</a></span></em> [<a href="http://dl.acm.org/citation.cfm?id=2212742&amp;amp;CFID=102411363&amp;amp;CFTOKEN=78064996">Paper</a>] [<a href="http://x10.sourceforge.net/documentation/papers/X10Workshop2011/elton_slides.pdf">Slides</a>]<br /> <span style="font-family: sans-serif; font-size: small;">by Robert Simmons, Frank Pfenning, and Bernardo Toninho</span><br /> <br /> <span style="font-family: sans-serif; font-size: small;"><strong>3:00 Break</strong></span><br /> <br /> <span style="font-family: sans-serif; font-size: small;"><strong>3:30 Session IV,</strong> Chair: <strong>Doug Lea</strong></span><br /> <em><span style="font-family: sans-serif; font-size: small;"><a href="#3">X10 on the Single-Chip Cloud Computer</a>&nbsp;&nbsp;</span></em> [<a href="http://dl.acm.org/citation.cfm?id=2212743&amp;amp;CFID=102411363&amp;amp;CFTOKEN=78064996">Paper</a>] [<a href="http://x10.sourceforge.net/documentation/papers/X10Workshop2011/X10 on the SCC.pdf">Slides</a>]<br /> <span style="font-family: sans-serif; font-size: small;">by Keith Chapman, Ahmed Hussein, and Antony L. Hosking</span><br /> <br /> <em><span style="font-family: sans-serif; font-size: small;"><a href="#10">GPU Programming in a High Level Language Compiling X10 to CUDA</a></span></em> [<a href="http://dl.acm.org/citation.cfm?id=2212744&amp;amp;CFID=102411363&amp;amp;CFTOKEN=78064996">Paper</a>] [<a href="http://x10.sourceforge.net/documentation/papers/X10Workshop2011/x10-gpu-slides.ppt">Slides</a>]<br /> <span style="font-family: sans-serif; font-size: small;">by David Cunningham, Rajesh Bordawekar, and Vijay Saraswat</span><br /> <br /> <em><span style="font-family: sans-serif; font-size: small;"><a href="#11">Phaser Beams: Integrating Stream Parallelism with Task Parallelism</a></span></em> [<a href="http://x10.sourceforge.net/documentation/papers/X10Workshop2011/x10-workshop-2011-shirako.v1.1.pdf">Slides</a>]<br /> <span style="font-family: sans-serif; font-size: small;">by Jun Shirako, David Peixotto, Dragos Sbirlea and Vivek Sarkar</span><br /> <br /> <span style="font-family: sans-serif; font-size: small;"><strong>5:00 X10 Roadmap and user community discussion - Michael Hind and Vijay Saraswat</strong></span><br /> &nbsp;</p>
<p><span style="font-family: sans-serif; font-size: small;"><strong>5:30 Workshop Concludes</strong></span></p>
<p>&nbsp;</p>
<hr />
<p>&nbsp;</p>
<p><a name="1"></a></p>
<h2>Parallel Programming: Design of an Overview Class</h2>
<h3><span>Christoph</span> von <span>Praun</span></h3>
<p>&nbsp;</p>
<h2>Summary</h2>
<p>We designed an introductory parallel programming course at the bachelor level. The class differs from other courses in its structure: The course is organized along the {\em tiers of parallelism}~\cite{Scott:<span>2009_MPEW</span>}. The tiers categorize abstractions and concepts that a software developer can choose when crafting a parallel program. The tiers are from higher to lower abstraction levels: (1) automatic/implicit parallelism, <span>e.g</span>., parallel libraries; (2) deterministic parallelism, <span>e.g</span>., at the level of independent loops; (3) explicitly synchronized, <span>e.g</span>., shared memory with locks; (4) low-level concurrent programming with data races, <span>e.g</span>., lock-free data structures. The goal of the class is to introduce fundamental principles of parallel systems and to expose students to all tiers in the architecture of a parallel system. The course serves as a platform for further exploration in specialized classes.</p>
<p>The course has a significant share of lab sessions and programming projects. We chose the programming language <span>X10</span> as the core technology and found that it facilitates the learning and rapid application of concepts at different abstraction layers and programming models. The language permits to specify common forms of parallelism, data sharing, distribution, and synchronization with succinct syntax and support for an eclipse-based IDE. We report on our first experience in teaching this course, which resulted in very positive student feedback.</p>
<p>&nbsp;</p>
<hr />
<p><a name="2"></a></p>
<h2>A Performance Model for <span>X10</span> Applications</h2>
<h3>David Grove, Olivier <span>Tardieu</span>, David Cunningham, Ben <span>Herta</span>, Igor <span>Peshansky</span> and Vijay <span>Saraswat</span></h3>
<p>&nbsp;</p>
<h2>Summary</h2>
<p>To reliably write high performance code in any programming language, an application programmer must have some understanding of the performance characteristics of the language's core constructs. We call this understanding a performance model for the language. Performance models are simultaneously defined and informed by the collection of implementation choices embodied in the programming language's compiler and runtime system. In this paper, we describe selected aspects of the implementation of version 2.2 of the <span>X10</span> programming language with the twin goals of establishing a useful performance model for the <span>X10</span> application programmer and to document aspects of the implementation that we believe are more generally applicable to other language implementation efforts.</p>
<p>&nbsp;</p>
<hr />
<p><a name="3"></a></p>
<h2><span>X10</span> on the Single-Chip Cloud Computer</h2>
<h3>Keith Chapman, Ahmed Hussein and Antony L. <span>Hosking</span></h3>
<p>&nbsp;</p>
<h2>Summary</h2>
<p>The Single-Chip Cloud Computer (<span>SCC</span>) is an experimental pro- <span>cessor</span> created by Intel Labs. <span>SCC</span> is essentially a "cluster-on-a- chip", so <span>X10</span> with its support for places and remote asynchronous invocations is a natural fit for programming this platform. We report here on our experience porting <span>X10</span> to the <span>SCC</span>, and show <span>perfor</span>- <span>mance</span> and scaling results for representative <span>X10</span> benchmark <span>appli</span>- <span>cations</span>. We compare results for our extensions to the <span>SCC</span> native messaging primitives in support of the <span>X10</span> run-time, versus <span>X10</span> on top of a prototype <span>MPI</span> API for <span>SCC</span>. The native <span>SCC</span> run-time exhibits better performance and scaling than the <span>MPI</span> binding. Scaling depends on the relative cost of computation versus communication in the workload used, since <span>SCC</span> is relatively underpowered for computation but has hardware support for message passing.</p>
<p>&nbsp;</p>
<hr />
<p><a name="4"></a></p>
<h2>Compiling <span>X10</span> to Java</h2>
<h3><span>Mikio</span> <span>Takeuchi</span>, Yuki <span>Makino</span>, <span>Kiyokuni</span> <span>Kawachiya</span>, <span>Hiroshi</span> <span>Horii</span>, <span>Toyotaro</span> <span>Suzumura</span>, <span>Toshio</span> <span>Suganuma</span> and <span>Tamiya</span> <span>Onodera</span></h3>
<p>&nbsp;</p>
<h2>Summary</h2>
<p><span>X10</span> is a new programming language for improving the software productivity in the <span>multicore</span> era by making the parallel/distributed programming easier. <span>X10</span> programs are compiled into C++ or Java source codes, however, <span>X10</span> supports various features not supported in Java. To handle them efficiently on Java, new compilation techniques become necessary. This paper discusses issues in translating <span>X10-unique</span> functions to Java, and provides our solutions. By using appropriate implementations, sequential execution performance has been improved by more than 7 times and now it is comparable to Java. Parallel execution performance has also been improved and the gap to Java Fork/Join performance is about 3 times when runs on a single place. Most of the results in this paper have already been incorporated in the latest <span>X10</span> release 2.1.2. The compilation techniques described in this paper are useful for implementing other programming languages targeted for Java or other managed environments.</p>
<p>&nbsp;</p>
<hr />
<p><a name="5"></a></p>
<h2>Object Initialization in <span>X10</span></h2>
<h3><span>Yoav</span> <span>Zibin</span>, David Cunningham, Igor <span>Peshansky</span> and Vijay <span>Saraswat</span></h3>
<p>&nbsp;</p>
<h2>Summary</h2>
<p><span>X10</span> is an object oriented programming language with a sophisticated type system (constraints, class <span>invariants</span>, non-erased generics, closures) and concurrency constructs (asynchronous activities, multiple places, global references). Object initialization is a crosscutting concern that interacts with all these features in delicate ways that may cause type-, runtime-, and security- errors. This paper discusses possible designs for object initialization, and the <span>&acirc;</span>&euro;<span>&oelig;hardhat&acirc;</span>&euro; design chosen and implemented in <span>X10</span> version 2.1. Our implementation includes a fixed-point inter-procedural (intra-class) data-flow analysis that infers, for each method called during initialization, the set of fields that are read and those that are asynchronously and synchronously assigned.</p>
<p>&nbsp;</p>
<hr />
<p><a name="6"></a></p>
<h2>Work-Stealing by Stealing States from Live Stack Frames of a Running Application</h2>
<h3><span>Vivek</span> Kumar, Daniel <span>Frampton</span>, David Grove, Olivier <span>Tardieu</span> and Steve Blackburn</h3>
<p>&nbsp;</p>
<h2>Summary</h2>
<p>The use of a work stealing scheduler has become a popular approach for providing task parallelism. It is used in many modern parallel programming languages, such as <span>Cilk</span> and <span>X10</span>, which have emerged to address the concerns of parallel programming complexity on modern <span>multicore</span> architectures. There are various challenges in providing an efficient implementation of work-stealing, but in any implementation it must be possible for the thief to access the execution state required to per- form the stolen task. The natural way to achieve this is to save the necessary state whenever a producer creates <span>stealable</span> work. While the ability to provide some degree of parallelism may dominate performance at scale, it is common for the vast majority of potentially <span>stealable</span> work to never actually be stolen, but instead processed by the producer itself. This indicates that to further improve performance we should minimize the overheads incurred in making work available for stealing. We are not the only ones to make this observation, for example <span>X10's</span> current C++ work-stealing implementation stack-allocates state objects and lazily copies them to the heap to avoid unnecessary heap allocation during normal execution. In our context of a Java virtual machine, it is possible to extend this idea further and avoid stack allocating state objects, but instead allow thieves to ex- tract state directly from within stack frames of the producer. This is achieved by using state-map information provided by a cooperative runtime compiler, allowing us to drive down the cost of making state available for <span>stealable</span> work items. We discuss our design and preliminary findings for the implementation of our framework in- side <span>X10</span> work-stealing runtime and the baseline compiler of <span>Jikes</span> <span>RVM</span>, a high-performance Java research virtual machine.</p>
<p>&nbsp;</p>
<hr />
<p><a name="7"></a></p>
<h2><span>X10</span> implementation of Parallel Option Pricing with <span>BSDE</span> method</h2>
<h3><span>Hui</span> Liu, Ying <span>Peng</span>, <span>DaiZhen</span> Wei and Bin <span>Dai</span></h3>
<p>&nbsp;</p>
<h2>Summary</h2>
<p>Option pricing is one of the most important parts in the field of financial derivatives pricing and risk management. To promote precision of pricing, we use an parallel method based on <span>BSDE</span>(Backward Stochastic Differential Equation) model, which is a widely used numerical model in financial computing <span>domain.BSDE</span> model can improve the accuracy and effectiveness of option pricing. <span>X10</span> is a high level high-performance programming language with new concurrency constructs, namely, places, <span>asyncs</span>, finish, atomic and clock. <span>X10</span> also provides a rich array language which includes region, distributions and distributed arrays. In this paper, we present how to utilize <span>X10's</span> properties to implement option pricing with <span>BSDE</span> model. Experimental results show that the parallel program implemented in <span>x10</span> can achieve a superior performance and nicer speedup. It can be widely used in financial area.</p>
<p>&nbsp;</p>
<hr />
<p><a name="8"></a></p>
<h2>Distributed deductive databases, <span>declaratively</span>: The <span>L10</span> logic programming language</h2>
<h3>Robert Simmons, Frank <span>Pfenning</span> and Bernardo <span>Toninho</span></h3>
<p>&nbsp;</p>
<h2>Summary</h2>
<p>We present the preliminary design of <span>L10</span>, a rich forward-chaining (<span>a.k.a</span>. "bottom-up") logic programming language. <span>L10</span> allows parallel computation to be explicitly specified through the use of *worlds*, a logically-motivated concept that has been used to describe distributed functional programming. An interpreter for <span>L10</span> runs these logic programs on top of the infrastructure of the <span>X10</span> programming language, and is responsible for mapping between <span>L10's</span> worlds and *places*, the related <span>X10</span> construct for describing distributed computation.</p>
<p>&nbsp;</p>
<hr />
<p><a name="9"></a></p>
<h2>Using the <span>Cowichan</span> Problems to Investigate the Programmability of <span>X10</span> Programming System</h2>
<h3><span>Jeeva</span> <span>Paudel</span> and Jose Nelson <span>Amaral</span></h3>
<p>&nbsp;</p>
<h2>Summary</h2>
<p>In today's era of <span>multicores</span> and clustered architectures, high performance and high productivity are central concerns in the design of parallel programming languages that aim to solve large computational problems. <span>X10</span> is a language based on state-of-the-art object-oriented programming ideas and claims to take advantage of their proven flexibility and ease- of-use to solve a wide spectrum of programming problems. The <span>Cowichan</span> problems is a set of computational problems that were designed to stress parallel programming environments and to assess their programmability. This paper uses <span>Cowichan</span> problems to assess the flexibility of <span>X10</span>.</p>
<p>&nbsp;</p>
<hr />
<p><a name="10"></a></p>
<h2><span>GPU</span> Programming in a High Level Language Compiling <span>X10</span> to <span>CUDA</span></h2>
<h3>David Cunningham, Rajesh <span>Bordawekar</span> and Vijay <span>Saraswat</span></h3>
<p>&nbsp;</p>
<h2>Summary</h2>
<p><span>GPU</span> architectures have emerged as a viable way of considerably improving performance for appropriate applications. Program fragments (kernels) appropriate for <span>GPU</span> execution can be implemented in <span>CUDA</span> or <span>OpenCL</span> and glued into an application via an API.</p>
<p>While there is plenty of evidence of performance improvements using this approach, there are many issues with productivity. Programmers must understand an additional programming model and API to program the accelerator; concurrency and synchronization in this programming model is typically expressed differently from the programming model for the host. On top of this, the languages used to write kernels are very low level and thus prone to the kinds of errors that one does not encounter in higher level languages. Programmers must explicitly deal with moving data back-and-forth between the host and the accelerator. These problems are compounded when the user code must be run across a cluster of accelerated nodes. Now the host programming model must further be extended with constructs to deal with scale-out and remote accelerators. We believe there is a critical need for a single source programming model that can be used to write clean, efficient code for heterogeneous, multi-core and scale-out architectures.</p>
<p>The <span>APGAS</span> programming model has been developed for such architectures over the past six years. <span>APGAS</span> is based on four fundamental (and architecture-independent) notions: locality, asynchrony, conditional <span>atomicity</span> and order. <span>X10</span> is an <span>instantiation</span> of the <span>APGAS</span> programming model on top of a base sequential language with Java-style productivity. Earlier work has shown that <span>X10</span> can be used to write clean and efficient code for homogeneous multi-cores, <span>SMPs</span>, Cell-accelerated nodes, and clusters of such nodes. In this paper we show how <span>X10</span> programmers can write code that can be compiled and run on <span>GPUs</span>. <span>GPU</span> programming idioms such as threads, blocks, barriers, constant memory, local registers, shared memory variables, etc. can be directly expressed in <span>X10</span>, and do not require new language extensions. We present the design of an extension of the <span>X10-to-C</span>++ compiler which recognizes such idioms and produces <span>CUDA</span> kernel code. We show several benchmarks written in this style. The performance of these kernels is within 80\% of hand-written <span>CUDA</span> kernels.</p>
<p>We believe these results establish <span>X10</span> as a single-source programming language in which clean, efficient programs can be written for <span>GPU-accelerated</span> clusters.</p>
<p>&nbsp;</p>
<hr />
<p><a name="11"></a></p>
<h2><span>Phaser</span> Beams: Integrating Stream Parallelism with Task Parallelism</h2>
<h3>Jun <span>Shirako</span>, David <span>Peixotto</span>, <span>Dragos</span> <span>Sbirlea</span> and <span>Vivek</span> <span>Sarkar</span></h3>
<p>&nbsp;</p>
<h2>Summary</h2>
<p>Current streaming languages place significant restrictions on the structure of parallelism that they support, and usually do not allow for dynamic task parallelism. In contrast, there are a number of task-parallel programming models that support dynamic parallelism but lack the ability to set up efficient streaming communications among dynamically varying sets of tasks. We address this gap by introducing <span>Phaser</span> Beams as a foundation for integrating stream parallelism with task parallelism. <span>Phaser</span> Beams builds on past work on accumulators and point-to-point synchronization in <span>Habanero-Java</span> (<span>HJ</span>) <span>phasers</span>, which in turn was derived from <span>X10</span> clocks.</p>
<p><span>Phaser</span> Beams introduce three key extensions relative to past work: 1) a bounded <span>phaser</span> that limits the maximum phase difference between a producer and a consumer synchronizing on that <span>phaser</span> and the buffer size needed to support streaming, 2) an extension to accumulators to work in non-barrier mode with bounded <span>phasers</span> for use in streaming, and 3) a dynamic cycle-detection algorithm to <span>phaser</span> registration to detect cyclic structures in a streaming program so as to enable efficient <span>batching</span> optimizations for <span>acyclic</span> structures. These extensions could easily be incorporated in a future version of <span>X10</span>.</p>
<p>Our preliminary Java-based implementation of <span>Phaser</span> Beams is restricted to the single node case, and the results obtained on three <span>multicore</span> <span>SMPs</span> are encouraging. As a calibration of the baseline performance of <span>phaser</span> synchronization, the performance of barriers in <span>HJ</span> <span>phasers</span> was found to be significantly faster than Java's <span>CyclicBarrier</span> and the Java and C++ implementations of <span>X10's</span> clocks, when measured using the <span>BarrierBench</span> benchmark.</p>
<p>We evaluate our <span>Phaser</span> Beams implementation using four streaming applications (<span>FilterBank</span>, <span>FMRadio</span>, <span>BeamFormer</span> from <span>StreamIt</span> benchmarks, and <span>FacilityLocation</span> to demonstrate combination of task and stream parallelism). The results are encouraging; the Java-based <span>Phaser</span> Beams implementation shows comparable performance to the C-based implementation of <span>StreamIt</span>.</p>
<p>&nbsp;</p>
<hr />
<p>&nbsp;</p>
<p><br /> <br /> &nbsp;</p>
